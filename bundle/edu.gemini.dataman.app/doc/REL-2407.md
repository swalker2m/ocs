## 2016A Data Manager Updates

Starting with the 2016A semester, Gemini will stop using the Gemini Science Archive provided by CADC and switch to an in-house archive and FITS storage service.  This change necessitates a number of corresponding updates to the OCS Data Manager application while also providing an opportunity to simplify the OCS codebase and incorporate all FITS processing services into a single application.  The purpose of this document is to catalog existing Data Manager functionality and take note of how, in each case, either the same functionality will be provided in the new system or else made obsolete.

In the sections that follow, Data Manager features are introduced in roughly the same order as they are needed in the lifespan of a dataset.

### Raw Dataset Copy

#### Pre-2016A

* The Data Manager polls the DHS directory looking for the appearance of new datasets.

  * It ignores all changes to datasets other than the arrival of new datasets.  That is, edits and deletes are not propagated.

  * It polls at a 2 minute frequency checking for any new datasets.

  * It polls at a 5 second frequency looking specifically for datasets that it expects will arrive soon.

* When it finds a new dataset, it is copied to the "dataflow" directory, which is available in a separate part of the netapps summit storage facility.

* The "dataflow" copy is updated with the `RELEASE` date header indicating when the dataset becomes public domain according to the following rules (program type - proprietary period):

  * C, DT, LP, Q - 18 months

  * FT - 6 months

  * SV - 3 months

  * CAL, ENG, any other program type - 0 months

* If the program has been marked with a special "private header" flag, a FITS header `PROP_MD` is added with a `true` value.

#### 2016A

The FITS storage service takes care of all these features.

> __WARNING:__ We missed the `PROP_MD` header detail in previous discussions.  Presumably the flag can be read from wherever   the contact scientist information is obtained.

> __WARNING:__ In pre-2016A code only C, DT, LP, Q, FT, SV, and CAL datasets are sent to the archive.  ENG and others are not sent. Since the Data Manager won't be looking at the files directly, all datasets must be archived or the OT will not know they exist.

### File / Database Synchronization

#### Pre-2016A

* The Data Manger polls the "dataflow" directory looking for new datasets and updates to existing datasets.

  * It polls at a 2 minute frequency checking for new, updated or deleted datasets.

  * It polls at a 5 second frequency looking specifically for datasets that it expects will arrive soon.

*  When it finds a new or updated dataset it either creates (if new) or makes any necessary changes to (if updated) the corresponding dataset record in the ODB.  In particular, the following items are tracked in the ODB and kept in sync with the corresponding FITS file:

  * Sync (update) time - By comparing the last update timestamp with the ODB timestamp, the Data Manager knows when it has potentially out-of-date information.

  * QA State

  * File State - File state tracks whether the file exists and if so, whether it is readable.

* The Data Manager watches for any changes to the QA State in dataset ODB records and makes the corresponding change to the header of the corresponding FITS file.

* Upon startup, the Data Manager must assume that the FITS files and database records may no longer be in sync.  Accordingly, it launches a process that reads every dataset on disk and every data set record in the database and synchronizes them.

#### 2016A

The Data Manager will no longer be working directly with FITS files or the "dataflow" directory.  Those responsibilities are now part of the FITS storage server.  Nevertheless we must keep an observation's dataset list and QA State up-to-date in the ODB as it is used for time accounting.  We must also assume that QA State can change at any time and without using the OT to make the update.  For example, DAs may go in to the "dataflow" directory and edit datasets directly with `hedit`.  In addition, the way that QA State is edited via the OT must change since the Data Manager will not be directly updating FITS files and cannot be sure that an update request will ultimately be successful.  (For example, there could be a network issue preventing the ODB from contacting the FITS storage server.)

##### Polling

All synchronization with the archive is handled in the ODB, avoiding the possibility of edit conflicts on the QA State.  The Data Manager will periodically poll the archive to obtain the current QA State and update the corresponding database records as necessary.  Here we anticipate different polling frequency depending on the situation:

> __WARNING:__ I'm not sure about these frequencies, please review.

* On demand.  Datasets for which the OT requests an immediate update (because a user is looking at the corresponding obs log).
* 5 min.  Datasets likely to be QAed which is defined as those that were obtained in the last 7 (?) days.
* 6 hrs.  Datasets belonging to programs from the last 2 semesters.
* 24 hrs.  All datasets.

A custom query is provided for this purpose.  It contains the content of the `jsonfilelist` along with the current QA State.

> __WARNING:__ I'll need this URL soon or else I can just use `jsonsummary` and pick out the bits that I need.

##### Dataset Record

The information associated with a dataset in the database changes in 2016A and beyond.  As before, we will track the dataset label, file name, creation date, and QA State.  The file state goes away in 2016A and the GSA State is vastly simplified.  In pre-2016A code, the file state is used to mark a dataset "gray" in the OT if it has not been found in the dataflow directory.  We no longer have direct access to the FITS files but we can similarly mark anticipated datasets (based on seqexec information) gray if they are not returned in archive queries.  This brings us to the GSA state.  Before, the process of sheparding datasets to the GSA was fairly onerous and replete with opportunities for failure.  In 2016A and beyond, we have less insight into the progress of a dataset through the system but we also face fewer opportunities for failure.  Archive state becomes either "None" (not yet found in the archive) or "Accepted".

> __WARNING:__ Currently we have no way of displaying additional information if a dataset cannot be read or accepted for some reason.

##### QA State Editing

The OT may still be used to set QA States but it will work differently in 2016A.  When a user sets a QA State it will make a  request to the ODB which will forward on the request to the FITS storage server.  The purpose of making the ODB the intermediary is to allow it to do the corresponding dataset record updates before returning.  The FITS storage server handles the request from the ODB synchronously so that when it successfully returns, we know that the QA States have been updated.

> __WARNING:__ This is a slightly different user experience than pre-2016A OT versions.  Before the QA States would be updated locally in the OT's copy of the program and the changes only stored when synchronized with the ODB.  The Data Manager in turn would watch the dataset records and know to update the FITS datasets.  In the new system, we cannot be sure that the request will work or how long it will take to work so we have to make this action display a popup 


